from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage, HumanMessage
from langgraph.graph import StateGraph, START, END, add_messages
from utils.llm import get_llm


class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]


def call_llm(state: AgentState):
    messages = state["messages"]
    response = get_llm().invoke(messages)
    return {"messages": [response]}


def create_langgraph_app():
    graph_builder = StateGraph(AgentState)

    # è®¾ç½®å…¥å£ç‚¹
    graph_builder.set_entry_point("call_model_node")
    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("call_model_node", call_llm)

    graph_builder.add_edge("call_model_node", END)

    # ç¼–è¯‘
    app = graph_builder.compile()

    return app


# æµ‹è¯•å¤šè½®å¯¹è¯
if __name__ == "__main__":
    app = create_langgraph_app()
    messages = []
    while True:
        user_input = input("ğŸ‘¤ You: ")
        if user_input.lower() in ["é€€å‡º", "exit", "quit"]:
            break
        messages.append(HumanMessage(content=user_input))

        inputs = {"messages": messages}
        for chunk in app.stream(inputs):
            if "call_model_node" in chunk:
                ai_msg = chunk["call_model_node"]["messages"][-1]
                print(f"ğŸ¤– Bot: {ai_msg.content}")
                messages.append(ai_msg)  # ä¿å­˜ AI å›å¤ï¼Œç”¨äºä¸‹ä¸€è½®
