import os
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END, add_messages
from utils.llm import get_llm
from utils.redis_connection import get_redis_checkpointer


class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]


def call_llm(state: AgentState):
    messages = state["messages"]
    response = get_llm().invoke(messages)
    return {"messages": [response]}


def create_langgraph_app():
    graph_builder = StateGraph(AgentState)

    # è®¾ç½®å…¥å£ç‚¹
    graph_builder.set_entry_point("call_model_node")
    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("call_model_node", call_llm)

    graph_builder.add_edge("call_model_node", END)

    # ç¼–è¯‘
    app = graph_builder.compile(checkpointer=get_redis_checkpointer())

    return app


# æµ‹è¯•å¤šè½®å¯¹è¯
if __name__ == "__main__":
    app = create_langgraph_app()
    config = {"configurable": {"thread_id": "user_test_1"}}  # å…³é”®ï¼å¿…é¡»æœ‰ thread_id
    while True:
        user_input = input("ğŸ‘¤ You: ")
        if user_input.lower() in ["é€€å‡º", "exit", "quit"]:
            break

        inputs = {"messages": [HumanMessage(content=user_input)]}

        for chunk in app.stream(inputs, config=config):
            if "call_model_node" in chunk:
                ai_msg = chunk["call_model_node"]["messages"][-1]
                print(f"ğŸ¤– Bot: {ai_msg.content}")
