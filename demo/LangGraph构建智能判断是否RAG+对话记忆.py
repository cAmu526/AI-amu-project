import os
from typing import TypedDict, Annotated, Sequence, Literal
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END, add_messages
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langchain_core.output_parsers import JsonOutputParser

from utils.llm import get_llm
from utils.postgresql_connection import get_pgsql_checkpointer
from utils.rag.chroma_store import get_retriever
from utils.logger import get_logger

logger = get_logger(__name__)


class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]


# === Step 1: å®šä¹‰åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢çš„ç»“æ„åŒ–è¾“å‡º ï¼Œç›¸å½“äºå®šä¹‰äº†ä¸€ä¸ªæ•°æ®ç»“æ„===
class NeedRetrieve(BaseModel):
    need_retrieve: bool = Field(description="æ˜¯å¦éœ€è¦ä»çŸ¥è¯†åº“æ£€ç´¢ä¿¡æ¯æ¥å›ç­”é—®é¢˜ã€‚")
    reason: str = Field(description="åˆ¤æ–­ç†ç”±ï¼ˆç”¨äºè°ƒè¯•ï¼‰")


# === Step 2: åˆ¤æ–­èŠ‚ç‚¹ï¼šæ˜¯å¦éœ€è¦ RAG ===
def should_retrieve(state: AgentState) -> dict:
    """
    ä½¿ç”¨ LLM åˆ¤æ–­å½“å‰é—®é¢˜æ˜¯å¦éœ€è¦æ£€ç´¢å¤–éƒ¨çŸ¥è¯†ã€‚
    è¿”å› "yes" æˆ– "no"ï¼Œç”¨äº LangGraph æ¡ä»¶è·¯ç”±ã€‚
    """
    # è·å–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯
    query = ""
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            query = msg.content
            break

    if not query:
        return {"route": "no"}

    # æ„é€ åˆ¤æ–­ prompt æ„å»ºä¸€ä¸ªç»“æ„åŒ–çš„èŠå¤©æç¤ºæ¨¡æ¿ï¼ˆChat Prompt Templateï¼‰ï¼Œç”¨äºå¼•å¯¼ LLM è¿›è¡Œæ£€ç´¢å¿…è¦æ€§åˆ¤æ–­ã€‚
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ¤æ–­ç”¨æˆ·çš„é—®é¢˜æ˜¯å¦éœ€è¦æŸ¥è¯¢å¤–éƒ¨çŸ¥è¯†åº“ï¼ˆå¦‚æ–‡æ¡£ã€æ•°æ®åº“ã€ä¸“ä¸šçŸ¥è¯†ï¼‰æ‰èƒ½å‡†ç¡®å›ç­”ã€‚\n"
                   "ä»…å½“é—®é¢˜æ¶‰åŠäº‹å®æ€§ã€ç‰¹å®šé¢†åŸŸçŸ¥è¯†ã€æ–‡æ¡£å†…å®¹ã€å†å²è®°å½•ç­‰æ—¶æ‰éœ€è¦æ£€ç´¢ã€‚\n"
                   "é—®å€™ã€é—²èŠã€é€šç”¨å¸¸è¯†ã€æŒ‡ä»¤ç±»é—®é¢˜ï¼ˆå¦‚'æ€»ç»“ä¸€ä¸‹'ï¼‰é€šå¸¸ä¸éœ€è¦æ£€ç´¢ã€‚"
                   "ä½ å¿…é¡»è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
                   '{{"need_retrieve": true/false, "reason": "ä½ çš„åˆ¤æ–­ç†ç”±"}}'),
        ("human", "é—®é¢˜ï¼š{question}")
    ])

    # ä½¿ç”¨è½»é‡çº§ LLMï¼ˆæˆ–ä¸» LLMï¼‰åšåˆ¤æ–­
    llm = get_llm()
    structured_llm = llm.with_structured_output(NeedRetrieve)
    # parser = JsonOutputParser(pydantic_object=NeedRetrieve)
    # LCELè¡¨è¾¾å¼
    # chain = prompt | llm | parser
    chain = prompt | structured_llm

    try:
        logger.info("llmåˆ¤æ–­ä¸­...")
        result = chain.invoke({"question": query})
        need = result.need_retrieve
        reason = result.reason
        # need = result.get('need_retrieve')
        # reason = result.get('reason')
        logger.info(f"RAG åˆ¤æ–­ï¼š{'éœ€è¦' if need else 'ä¸éœ€è¦'}æ£€ç´¢ | ç†ç”±: {reason}")
        return {"route": "yes" if need else "no"}

    except Exception as e:
        logger.error(f"âš ï¸ RAG åˆ¤æ–­å‡ºé”™ï¼Œé»˜è®¤ä¸æ£€ç´¢: '{e}'")
        return {"route": "no"}


def retrieve(state: AgentState):
    """
    æ£€ç´¢èŠ‚ç‚¹ï¼šä»æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸­æå–æŸ¥è¯¢ï¼Œè¿›è¡Œå‘é‡æ£€ç´¢ã€‚
    """
    # è·å–æœ€æ–°çš„ç”¨æˆ·è¾“å…¥ï¼ˆé€šå¸¸æ˜¯æœ€åä¸€æ¡ HumanMessageï¼‰
    query = ""
    for msg in reversed(state["messages"]):
        if isinstance(msg, HumanMessage):
            query = msg.content
            break

    if not query:
        return {"messages": []}  # æ— æŸ¥è¯¢åˆ™è·³è¿‡

    # è°ƒç”¨æ£€ç´¢å™¨ï¼ˆé»˜è®¤ collectionï¼Œå¯æŒ‰éœ€ä¼ å‚ï¼‰
    logger.info("ragæ£€ç´¢...")
    retriever = get_retriever()
    docs: list[Document] = retriever.invoke(query)

    # å°†æ£€ç´¢ç»“æœæ ¼å¼åŒ–ä¸ºæ–‡æœ¬ä¸Šä¸‹æ–‡
    context = "\n\n".join([doc.page_content for doc in docs])

    # æ„é€ å¢å¼ºåçš„ç³»ç»Ÿæç¤ºï¼ˆæˆ–ç›´æ¥æ‹¼æ¥åˆ°ç”¨æˆ·æ¶ˆæ¯ï¼‰
    augmented_user_message = HumanMessage(
        content=(
            f"è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸ç›¸å…³ï¼Œè¯·å›ç­”ï¼šæˆ‘çš„çŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯ã€‚\n\n"
            f"ä¸Šä¸‹æ–‡ï¼š\n{context}\n\n"
            f"é—®é¢˜ï¼š{query}"
        )
    )

    # æ›¿æ¢åŸå§‹ç”¨æˆ·æ¶ˆæ¯ä¸ºå¢å¼ºç‰ˆï¼ˆä¿ç•™å†å²å¯¹è¯ç»“æ„ï¼‰
    new_messages = []
    for msg in state["messages"]:
        if isinstance(msg, HumanMessage) and msg.content == query:
            new_messages.append(augmented_user_message)
        else:
            new_messages.append(msg)

    return {"messages": new_messages}


def call_llm(state: AgentState):
    messages = state["messages"]
    logger.info("call_llmå›å¤æœ€åç»“æœ...")
    response = get_llm().invoke(messages)
    return {"messages": [response]}


def create_langgraph_app():
    graph_builder = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("judge_retrieve", should_retrieve)  # åˆ¤æ–­èŠ‚ç‚¹ï¼ˆä¸ä¿®æ”¹ stateï¼‰
    graph_builder.add_node('retrieve', retrieve)
    graph_builder.add_node("call_model_node", call_llm)

    graph_builder.add_edge(START, "judge_retrieve")
    # æ¡ä»¶è¾¹ï¼šæ ¹æ® judge_retrieve çš„è¿”å›å€¼å†³å®šèµ°å‘
    graph_builder.add_conditional_edges(
        "judge_retrieve",  # ç”¨äºåˆ¤æ–­çš„èŠ‚ç‚¹çš„ç»“æœ
        lambda x: x['route'],  # ä¸Šä¸€ä¸ªèŠ‚ç‚¹æ‰§è¡Œçš„should_retrieveæ–¹æ³• å…¶è¿”å›çš„æ˜¯ "yes"/"no"ï¼Œæ‰€ä»¥è¿™é‡Œåªç”¨ä¸€ä¸ªlambdaè¡¨è¾¾å¼å†™çš„ç®€å•åŒ¿åå‡½æ•°ä½œä¸ºè·¯ç”±å‡½æ•°
        {
            "yes": "retrieve",
            "no": "call_model_node"
        }
    )

    graph_builder.add_edge("retrieve", "call_model_node")
    graph_builder.add_edge("call_model_node", END)

    # ç¼–è¯‘
    app = graph_builder.compile(checkpointer=get_pgsql_checkpointer())

    return app


# æµ‹è¯•å¤šè½®å¯¹è¯
if __name__ == "__main__":
    app = create_langgraph_app()
    config = {"configurable": {"thread_id": "user_test_2"}}  # å…³é”®ï¼å¿…é¡»æœ‰ thread_id
    while True:
        user_input = input("ğŸ‘¤ You: ")
        if user_input.lower() in ["é€€å‡º", "exit", "quit"]:
            break

        inputs = {"messages": [HumanMessage(content=user_input)]}

        for chunk in app.stream(inputs, config=config):
            if "call_model_node" in chunk:
                ai_msg = chunk["call_model_node"]["messages"][-1]
                print(f"ğŸ¤– Bot: {ai_msg.content}")
